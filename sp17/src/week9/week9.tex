\documentclass{exam}
\usepackage{commonheader}
\printanswers
%%% CHANGE THESE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\discnumber{5}
\title{\textsc{Orders of Growth}}
\date{March 13 to March 17, 2016}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\rule{\textwidth}{0.15em}
\fontsize{12}{15}\selectfont

%%% INCLUDE TOPICS HERE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%% Question %%%

\begin{questions}

\begin{blocksection}
\question \textbf{Fast Exponentiation:} in this problem, we will examine a
real-world algorithm used to improve the speed of calculating exponents.

\begin{parts}

\part First, express the runtime of the naive exponentiation algorithm in big-O
notation.
\begin{lstlisting}
def exp(b, n):
    if n == 0:
        return 1
    else:
        return b * exp(b, n - 1)
\end{lstlisting}
\begin{solution}[0.25in]
$\Theta(n)$. $n$ decreases by 1 each call, so there are naturally $n$ calls.
\end{solution}

\part Now, express the runtime of the fast exponentiation algorithm in big-O
notation.
\begin{lstlisting}
def fast_exp(b, n):
    if n == 0:
        return 1
    if n % 2 == 0: # Assume square runs in constant time
        return square(fast_exp(b, n // 2))
    return b * fast_exp(b, n - 1)
\end{lstlisting}
\begin{solution}[0.25in]
$\Theta(\log n)$. $n$ is halved each call, so the number of calls is the number of
times $n$ must be halved to get to 1. This is $\log n$.
\end{solution}


\part What about this slightly modified version of \texttt{fast\char`_exp}?
\begin{lstlisting}
def fast_exp(b, n):
    for _ in range(50 * n):
        print("Killing time")
    if n == 0:
        return 1
    if n % 2 == 0:
        return square(fast_exp(b, n // 2))
    return b * fast_exp(b, n - 1)
\end{lstlisting}
\begin{solution}
$\Theta(n)$. Ignore the constant term. The first call will perform $n$ operations,
the second call will perform $n / 2$ operations, the third will perform $n / 4$
operations, etc. Using geometric series, we see this adds up to $2n$, which is
$n$ if we ignore constant terms.
\end{solution}


\end{parts}
\end{blocksection}

\begin{blocksection}


\question \textbf{Mysterious loops:} What is the order of growth in time for the following functions? Use big-O notation.

\begin{parts}

\part
\begin{lstlisting}
def mystery(n):
    for i in range(n):
        while i % 2 != 0:
            print(i)
            i = i - 1
        print("Done")
\end{lstlisting}
\begin{solution}[0.25in]
$\Theta(n)$. The work for when $i$ is divisible by two is constant. Subtracting one
will immediately allow us to exit the \texttt{while} loop. Therefore, we can
concentrate on just the outer loop.
\end{solution}

\part
\begin{lstlisting}
def fun(n):
    for i in range(n):
        for j in range(n * n):
            if j == 4:
                return -1
            print("Fun!")
\end{lstlisting}
\begin{solution}[0.25in]
$\Theta(1)$. Inner loop always immediately exits after running for 4 iterations,
independent of $n$.
\end{solution}

\end{parts}
\end{blocksection}

\begin{blocksection}
\question \textbf{Orders of Growth and Trees:} Assume we are using the non-mutable Tree implementation introduced in discussion. Consider the following function:
\begin{lstlisting}
def word_finder(t, n, word):
    if root(t) == word:
        n -= 1
        if n == 0:
            return True
    for branch in branches(t):
        if word_finder(branch, n, word):
            return True
    return False
\end{lstlisting}

\begin{parts}
\part What does this function do?  \newline
\begin{solution}[0.25in]
This function take a Tree \texttt{t}, an integer \texttt{n}, and a string
\texttt{word} in as input.

Then, \texttt{word\char`_finder} returns True if any paths from the root towards
the leaves have at least \texttt{n} occurrences of the word and False otherwise.
\end{solution}

\part If a tree has $n$ total nodes, what is the total runtime for all searches
in big-O notation?
\begin{solution}[0.25in]
$\Theta(n)$. At worst, we must visit every node of the tree.
\end{solution}

\end{parts}

\end{blocksection}
\pagebreak
\pagebreak

\begin{blocksection}
\question \textbf{Orders of Growth and Linked Lists:} For reference, here is our implementation of a Linked List:
\begin{lstlisting}
class Link:
    empty = ... #The empty list, implementation not shown.
    def __init__(self, first, rest=empty):
        assert rest is Link.empty or isinstance(rest, Link)
        self.first = first
        self.rest = rest
    def __repr__(self): # implementation not shown
        '''Displays a Link in a more readable manner.
        
\end{lstlisting}

Consider the following linked list function:
\begin{lstlisting}
def insert_at_beginning(lst, x):
    return Link(x, lst)
\end{lstlisting}

\end{blocksection}
\begin{blocksection}

\begin{parts}
\part What does this function do?

\begin{solution}
It takes in an existing lst and returns a new list with $x$ at the front.
\end{solution}

\part Assume lst is initially length $n$. How long does it take to do one
insert? Two? $n$?
\begin{solution}
All inserts will take constant time. No matter how long the list is, it doesn't
take any longer to add to the front. One insert will take one unit of time, and
two will take roughly twice that. Therefore, the amount of time to do $n$
inserts will be $\Theta(n)$.
\end{solution}

Now consider:
\begin{lstlisting}
def insert_at_end(lst, x):
    if lst.rest is Link.empty:
        lst.rest = Link(x)
    else:
        insert_at_end(lst.rest, x)
\end{lstlisting}

\part What does this function do?
\begin{solution}[0.25in]
    Inserts a value \texttt{x} at the end of linked list \texttt{lst}.
\end{solution}
\part Say we want to repeatedly insert some numbers into the end of a linked
list:
\begin{lstlisting}
def insert_many_end(lst, n):
    for i in range(n):
        insert_at_end(lst, i)
\end{lstlisting}
\begin{subparts}

\subpart Assume \texttt{lst} is initially length 1. How long will it take to do
the first insertion? The second? The $n$th?
\begin{solution}[0.25in]
Notice that the list gets longer with each insertion, so each operation will
make it harder to do the next.
Therefore, the first insertion will take about 1 unit of time. The second will
take about twice as long, at two units of time. The $n$th insertion will take
$n$ units of time.
\end{solution}

\subpart In big-O notation, What is the total runtime to do all the inserts?
(total runtime of \texttt{insert\char`_many\char`_end})
\begin{solution}[0.25in]
The total runtime will be the sum of all the inserts: 1 + 2 + 3 + \ldots + $n$ =
$\frac{n (n + 1)}{2}$ = $\Theta(n^{2})$
\end{solution}

\end{subparts}

\end{parts}
\end{blocksection}

\begin{blocksection}

\question \textbf{This is a question about Box-and-Pointer diagrams.} Please refer to the Linked List implementation from the previous question.

\begin{parts}
\part Fill in the box and pointer diagram that follows the execution of this code.
\begin{lstlisting}
x = Link(2, Link(5, Link(5)))
y = Link(2, Link(4, Link(6)))
x.rest, y.rest = y.rest, x.rest

def peanutbutter(z):
    if z == Link.empty:
        return Link.empty
    x.first = x.first * z.first
    if z.first % 2 == 0:
        return Link(z.first, peanutbutter(z.rest))
    return Link(Link(x.first))
	
jelly = peanutbutter(y)

\end{lstlisting}

\begin{center}
\includegraphics[scale=0.8]{5a_new}
\end{center}
\end{parts}
\end{blocksection}
\begin{blocksection}
\begin{solution}[0.25in]
\begin{center}
\includegraphics[scale=0.8]{5a_sol_new}
\end{center}
\end{solution}
\end{blocksection}




\end{questions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}


